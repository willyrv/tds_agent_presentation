---
marp: true
theme: default
class: lead
paginate: true
footer: "AI Autonomous Agents â€” 2025"
title: "AI Autonomous Agents â€” From LLMs to Model Context Protocols and Real-World Systems"
---

# ğŸ¤– AI Autonomous Agents  
### From LLMs to Model Context Protocols and Real-World Systems  
**Speaker:** Willy RODRIGUEZ
**Organization:** Toulouse Data Science
**Duration:** ~45 minutes

---

## ğŸ§­ Motivation

- LLMs are no longer just chatbots â€” they can **plan, act, and learn**.  
- We are witnessing the shift from *assistants* â†’ *autonomous agents*.  
- Agents can:  
  - Use tools  
  - Access external data  
  - Make decisions autonomously  

ğŸ§© **Goal of this talk:**  
Understand *how* this autonomy works and see *whatâ€™s possible* today.

---

## Outline

1. Large Language Models â€” quick refresher  
2. Architectures for agentic systems  
3. The Model Context Protocol (MCP)  
4. Real-world demos and open-source stack  
5. Discussion & future directions

---

## 1ï¸âƒ£ What Are Large Language Models?

- Based on the **Transformer** architecture (Vaswani et al., 2017)  
- Trained on massive text corpora â†’ emergent reasoning abilities  
- Key properties:  
  - In-context learning  
  - Chain-of-thought reasoning  
  - Function calling / tool use  

ğŸ“ˆ *Scaling laws â†’ more data + compute â†’ emergent behavior*

---

## âš™ï¸ Quick Recap: Transformer Architecture

**Core idea:** Attention mechanism learns contextual dependencies  
- Self-Attention: \( \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V \)  
- Enables parallelism & long-range dependencies  

ğŸ§  *Result: a model that can encode meaning across long sequences.*

```mermaid
graph TD
A[Input Tokens] --> B[Embedding Layer]
B --> C[Multi-Head Self-Attention]
C --> D[Feed Forward Network]
D --> E[Output Tokens]
```

---

## ğŸŒ LLM Landscape (2025)

| Category	| Models | Notes
------|-----|-----| 
Proprietary	| GPT-4o, Claude 3, Gemini 1.5	| Multimodal, highly optimized
Open Source | Llama-3, Mistral, Mixtral, Falcon, Yi | Customizable and efficient
Agent Frameworks | LangChain, CrewAI, AutoGen, OpenDevin | Enable reasoning + action



ğŸ“Š *Open models now rival closed ones in many benchmarks.*


---

## From LLMs to Agents

LLMs â‰  Agents

| LLM	| Agent | 
------|-----| 
Predicts next token	| Executes tasks
Static context | Dynamic memory
No persistence | Has tools & goals


**Agent loop:** â†’ Plan â†’ Act â†’ Observe â†’ Reflect â†’ Repeat

```
A[Plan] --> B[Act]
B --> C[Observe]
C --> D[Reflect]
D --> A
```
---

## ğŸ§© Core Components of an Agent

* Planner / Controller â€” LLM orchestrates reasoning
* Tools / APIs â€” perform external actions (search, code exec, etc.)
* Memory â€”
  * Short-term: context window
  * Long-term: vector store / RAG
* Environment â€” user interface, web, or local system

```graph TD
A[User] --> B[Agent Controller]
B --> C[LLM Reasoning Core]
B --> D[Memory Store]
B --> E[Tool / API Interfaces]
C --> F[Action Output]
```

---

## ğŸ§  Example: ReAct Framework (Yao et al., 2022)

Agents interleave reasoning traces with actions.

Example trace:

```vbnet
Thought: I need the current weather.
Action: call(weather_api, "Toulouse")
Observation: 21Â°C, sunny
Thought: I'll tell the user it's sunny.
Answer: It's 21Â°C and sunny in Toulouse.
```

---

## ğŸ›°ï¸ Model Context Protocol (MCP)
A new standard for connecting models to tools

Goal: Let models interact with external systems via a standardized interface

Adopted by: Anthropic (Claude), OpenAI, and open implementations

Defines:

* Servers = tools, resources, schemas
* Clients = LLM runtime interfaces
* Models = consume structured responses

```graph LR
A[LLM] <--> B[MCP Client]
B <--> C[MCP Server]
C --> D[(APIs / Databases / Files)]
```

---

## ğŸ§± MCP Architecture

Step-by-step interaction

1. Model sends request (list_resources, invoke_tool, etc.)
2. MCP server executes function & returns structured JSON
3. Model integrates results into reasoning context

Example schema:
```json
{
  "name": "get_weather",
  "parameters": { "city": "Toulouse" },
  "returns": { "temp": "float", "condition": "string" }
}
```
---

## âš–ï¸ MCP vs Other Architectures


Feature | Function Calling | LangChain | MCP
---|---|---|---
Vendor neutral | âŒ | âŒ | âœ…
Schema registry | âš ï¸ | âœ… | âœ…
Model-driven control | âœ… | âœ… | âœ…
Plug-and-play tools | âŒ | âš ï¸ | âœ…

---

## ğŸ“¡ MCP aims to be the â€œHTTP of agent tool use.â€

3ï¸âƒ£ Real-World Examples
Proprietary Ecosystems

Claude 3 + MCP: direct server integration (file systems, APIs)

Gemini 1.5: multi-modal reasoning + contextual memory

GPT-4o: real-time voice + visual tool use

(Short video clip or screenshots)

---

ğŸ§ª Open-Source Demo Idea
â€œAutonomous Research Assistantâ€

Stack:

Model: Llama-3 8B (via Ollama or LM Studio)

Framework: LangGraph or CrewAI

Tools: Arxiv API (via MCP server) + local RAG memory

Goal: Summarize papers about â€œTopic Modelingâ€ autonomously

```graph LR
A[Llama-3 Agent] --> B[MCP Server]
B --> C[Arxiv API]
B --> D[(Vector DB)]
```

---

## Demo Flow

1. User asks: â€œFind 3 recent papers on diffusion transformers.â€
2. Agent:
  * Searches Arxiv
  * Summarizes abstracts
  * Ranks results
  * Produces a final report
3. Output displayed in terminal or web UI

ğŸ§  Shows reasoning â†’ action â†’ synthesis loop.

---

## Alternative Demo: Voice Agent (Fully Open)

Stack:
* Whisper (speech-to-text)
* Llama-3 (reasoning)
* Piper or Coqui TTS (speech synthesis)
* MCP for tasks (weather, notes, etc.)

ğŸ™ï¸ â€œHey assistant, summarize todayâ€™s AI news.â€
â†’ Spoken answer generated locally!

--- 

## ğŸ§­ Challenges Ahead

* Reliability & hallucination control

* Memory consistency & long-term goals

* Security & sandboxing for tool execution

* Evaluation metrics for autonomy

---

## ğŸ”® Future Directions

* Multi-agent collaboration (CrewAI, AutoGen)

* Embodied agents (robotics integration)

* Fine-tuned tool-use (Toolformer-style)

* AI Operating Systems (MCP-based infrastructure)

ğŸ“ˆ Agents as the next layer of abstraction â€” like containers for cognition.

---

## ğŸ§© Key Takeaways

* LLMs are reasoning engines

* Agents give them tools, memory, and goals

* MCP enables standardized, safe interoperability

* Open-source tools now make fully local agents possible

---

## ğŸ“š Suggested Reading

* Yao et al., ReAct: Reasoning and Acting in Language Models (2022)

* Schick et al., Toolformer (2023)

* Anthropic, Model Context Protocol Specification (2024)

* LangChain / LangGraph Docs

* CrewAI / AutoGen Projects

---

### ğŸ™ Thank You

ğŸ’¡ â€œLLMs gave us reasoning. MCP gives them agency.â€
Questions?

