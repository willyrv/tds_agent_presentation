---
marp: true
theme: default
paginate: true
header: 'Agents Autonomes IA'
footer: 'Toulouse Data Science'
math: katex
---

<!-- _class: lead -->
# ü§ñ Agents Autonomes IA
## Des LLMs aux Protocoles MCP et aux Syst√®mes Op√©rationnels

**Intervenant :** Willy RODRIGUEZ  
**Organisation :** Toulouse Data Science  
**Dur√©e :** ~45 minutes (plus ou moins)

---

# Motivation

- Les LLMs ne sont plus seulement des chatbots ‚Äî ils peuvent planifier, agir et apprendre.
- Nous assistons √† la transition des assistants vers de v√©ritables agents autonomes.
- Les agents peuvent :
  - Utiliser des outils
  - Acc√©der √† des donn√©es externes
  - Prendre des d√©cisions de mani√®re autonome

**Objectif :**  
Comprendre comment fonctionne cette autonomie et ce qui est possible aujourd'hui.

---

# Plan de la pr√©sentation

1. Rappel rapide sur les LLMs
2. Architectures des syst√®mes agentiques
3. Le Model Context Protocol (MCP)
4. D√©mos r√©elles + stack open-source
5. Discussion & perspectives

---

# Qu'est-ce qu'un Large Language Model (LLM) ?

- Bas√© sur l'architecture Transformer (Vaswani et al., 2017)
- Entra√Æn√© sur d'immenses corpus ‚Üí capacit√©s de raisonnement √©mergentes
- Caract√©ristiques cl√©s :
  - Apprentissage in-context
  - Raisonnement cha√Æne-de-pens√©es
  - Function calling / outils

**Plus de donn√©es + plus de calcul ‚Üí comportements √©mergents.**

---

# Rappel : Architecture Transformer

**Id√©e centrale :** le m√©canisme d'attention capture les d√©pendances contextuelles

- Self-Attention : $\text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V$
- Permet le parall√©lisme et les d√©pendances longues

**R√©sultat :** un mod√®le capable d'encoder du sens sur de longues s√©quences.

---
# Transformer

![Architecture Transformer](images/transformer-architecture.png)
---

# √âcosyst√®me LLM (2025)

**Propri√©taires :**
- GPT-5, GPT-4o, Claude 4 Opus, Claude 3.5 Sonnet
- Gemini 2.5 Pro, Gemini 3, Grok 4

**Open source :**
- Llama 4, Llama 3, Mistral 8x22B, Qwen3
- DeepSeek R1, DeepSeek-V3, Gemma 3

**Frameworks d'agents :**
- LangChain, CrewAI, AutoGen, OpenDevin

Les mod√®les open rivalisent d√©sormais avec les mod√®les propri√©taires.

---

# Des LLMs aux Agents

## LLM ‚â† Agent

**LLM :**
- Pr√©dit le prochain token
- Contexte statique
- Pas de persistance

**Agent :**
- Ex√©cute des t√¢ches
- M√©moire dynamique
- Dispose d'outils & d'objectifs

**Boucle agent :** Planifier ‚Üí Agir ‚Üí Observer ‚Üí R√©fl√©chir ‚Üí R√©p√©ter

---

![Function Calling avec Hugging Face](images/function-calling_huggingface.png)

---

# Composants essentiels d'un agent

- **Planificateur / Contr√¥leur** ‚Äî le LLM orchestre le raisonnement
- **Outils / APIs** ‚Äî actions externes (recherche, ex√©cution de code‚Ä¶)
- **M√©moire :**
  - Court terme : fen√™tre de contexte
  - Long terme : base vectorielle / RAG
- **Environnement :** interface utilisateur, web, syst√®me local

---

# Exemple : ReAct (Yao et al., 2022)

Les agents alternent raisonnement et actions.

**Exemple :**

```
Thought : J'ai besoin de la m√©t√©o actuelle.
Action : call(weather_api, "Toulouse")
Observation : 21¬∞C, ensoleill√©
Thought : Je vais transmettre cette info.
Response : Il fait 21¬∞C et ensoleill√© √† Toulouse.
```

---

# Model Context Protocol (MCP)

Un nouveau standard pour connecter les mod√®les aux outils.

**Objectif :** permettre aux mod√®les d'interagir avec des syst√®mes externes via une interface standardis√©e.

Adopt√© par Anthropic, OpenAI et la communaut√© open-source.

**D√©finit :**
- Serveurs = outils, ressources, sch√©mas
- Clients = environnements d'ex√©cution des LLMs
- Mod√®les = consomment des r√©ponses structur√©es

---

![Architecture MCP](images/mcp-architecture.png)

---

# Architecture MCP

**√âtapes :**

1. Le mod√®le envoie une requ√™te (list_resources, invoke_tool‚Ä¶)
2. Le serveur MCP ex√©cute et renvoie du JSON structur√©
3. Le mod√®le int√®gre la r√©ponse dans son raisonnement

**Exemple :**
```json
{
  "name": "get_weather",
  "parameters": { "city": "Toulouse" },
  "returns": { "temp": "float", "condition": "string" }
}
```

---

# MCP : le "HTTP de l'usage d'outils par les agents"

**Exemples propri√©taires :**
- Claude 3 + MCP : syst√®mes de fichiers, API
- Gemini 1.5 : raisonnement multimodal + m√©moire
- GPT-4o : voix en temps r√©el + outils visuels

---

# D√©mo open-source : "Assistant de recherche autonome"

**Stack :**
- Llama-3 8B (Ollama / LM Studio)
- LangGraph ou CrewAI
- Arxiv API via MCP + m√©moire RAG locale

**Objectif :** r√©sumer des articles sur le Topic Modeling

---

# D√©roulement de la d√©mo

1. L'utilisateur demande : *"Trouve 3 articles r√©cents sur les diffusion transformers."*
2. L'agent :
   - Interroge Arxiv
   - R√©sume les abstracts
   - Classe les r√©sultats
   - Produit un rapport
3. R√©sultat affich√© en terminal ou web

---

# Autre d√©mo : Agent vocal (100% open source)

**Stack :**
- Whisper (STT)
- Llama-3 (raisonnement)
- Piper / Coqui (TTS)
- MCP pour les t√¢ches

**Exemple :**
*"Assistant, r√©sume les actualit√©s IA du jour."*  
‚Üí R√©ponse parl√©e g√©n√©r√©e localement.

---

# D√©fis

- Fiabilit√© & r√©duction des hallucinations
- Coh√©rence de la m√©moire & objectifs long terme
- S√©curit√© & sandboxing
- M√©triques d'√©valuation de l'autonomie

---

# Utilisations avanc√©es des agents

Approches sophistiqu√©es pour d√©ployer des agents autonomes :

- **Collaboration multi-agents** ‚Äî plusieurs agents travaillent ensemble
- **Agents incarn√©s** ‚Äî int√©gration robotique et physique
- **Outils fine-tuned** ‚Äî mod√®les sp√©cialis√©s pour l'utilisation d'outils (Toolformer)
- **OS d'Agents** ‚Äî infrastructure d√©di√©e bas√©e sur MCP

**Les agents deviennent une nouvelle couche d'abstraction ‚Äî un "container" pour la cognition.**

---

# √Ä retenir

- Les LLMs sont des moteurs de raisonnement
- Les agents leur donnent des outils, de la m√©moire et des objectifs
- MCP standardise une interop√©rabilit√© s√ªre
- L'open-source permet des agents locaux et autonomes

---

# Quelques R√©f√©rences

- ReAct (Yao et al., 2022)
- Toolformer (Schick et al., 2023)
- Model Context Protocol Spec (2024)
- LangChain / LangGraph
- CrewAI / AutoGen

---

<!-- _class: lead -->
# üôè Merci !

*"Les LLMs fournissent les capacit√©s d'inf√©rence et de raisonnement symbolique. MCP standardise l'agentivit√© via une interface d'interaction avec des syst√®mes externes."*

**Questions ?**

