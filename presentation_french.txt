==================== SLIDE ====================
ğŸ¤– Agents Autonomes IA
Des LLMs aux Protocoles MCP et aux SystÃ¨mes OpÃ©rationnels
Intervenant : Willy RODRIGUEZ
Organisation : Toulouse Data Science
DurÃ©e : ~45 minutes

==================== SLIDE ====================
ğŸ§­ Motivation

- Les LLMs ne sont plus seulement des chatbots â€” ils peuvent planifier, agir et apprendre.
- Nous assistons Ã  la transition des assistants vers de vÃ©ritables agents autonomes.
- Les agents peuvent :
  - Utiliser des outils
  - AccÃ©der Ã  des donnÃ©es externes
  - Prendre des dÃ©cisions de maniÃ¨re autonome

Objectif :
Comprendre comment fonctionne cette autonomie et ce qui est possible aujourdâ€™hui.

==================== SLIDE ====================
Plan de la prÃ©sentation

1. Rappel rapide sur les LLMs
2. Architectures des systÃ¨mes agentiques
3. Le Model Context Protocol (MCP)
4. DÃ©mos rÃ©elles + stack open-source
5. Discussion & perspectives

==================== SLIDE ====================
1ï¸âƒ£ Quâ€™est-ce quâ€™un Large Language Model ?

- BasÃ© sur lâ€™architecture Transformer (Vaswani et al., 2017)
- EntraÃ®nÃ© sur dâ€™immenses corpus â†’ capacitÃ©s de raisonnement Ã©mergentes
- CaractÃ©ristiques clÃ©s :
  - Apprentissage in-context
  - Raisonnement chaÃ®ne-de-pensÃ©es
  - Function calling / outils

Plus de donnÃ©es + plus de calcul â†’ comportements Ã©mergents.

==================== SLIDE ====================
âš™ï¸ Rappel : Architecture Transformer

IdÃ©e centrale : le mÃ©canisme dâ€™attention capture les dÃ©pendances contextuelles
- Self-Attention : softmax(QKáµ€ / âˆšdâ‚–) V
- Permet le parallÃ©lisme et les dÃ©pendances longues

RÃ©sultat : un modÃ¨le capable dâ€™encoder du sens sur de longues sÃ©quences.

==================== SLIDE ====================
ğŸŒ Ã‰cosystÃ¨me LLM (2025)

PropriÃ©taires :
- GPT-4o, Claude 3, Gemini 1.5
Open source :
- Llama-3, Mistral, Mixtral, Falcon, Yi
Frameworks dâ€™agents :
- LangChain, CrewAI, AutoGen, OpenDevin

Les modÃ¨les open rivalisent dÃ©sormais avec les modÃ¨les propriÃ©taires.

==================== SLIDE ====================
Des LLMs aux Agents

LLM â‰  Agent

LLM :
- PrÃ©dit le prochain token
- Contexte statique
- Pas de persistance

Agent :
- ExÃ©cute des tÃ¢ches
- MÃ©moire dynamique
- Dispose dâ€™outils & dâ€™objectifs

Boucle agent : Planifier â†’ Agir â†’ Observer â†’ RÃ©flÃ©chir â†’ RÃ©pÃ©ter

==================== SLIDE ====================
ğŸ§© Composants essentiels dâ€™un agent

- Planificateur / ContrÃ´leur â€” le LLM orchestre le raisonnement
- Outils / APIs â€” actions externes (recherche, exÃ©cution de codeâ€¦)
- MÃ©moire :
    - Court terme : fenÃªtre de contexte
    - Long terme : base vectorielle / RAG
- Environnement : interface utilisateur, web, systÃ¨me local

==================== SLIDE ====================
ğŸ§  Exemple : ReAct (Yao et al., 2022)

Les agents alternent raisonnement et actions.

Exemple :

PensÃ©e : Jâ€™ai besoin de la mÃ©tÃ©o actuelle.
Action : call(weather_api, "Toulouse")
Observation : 21Â°C, ensoleillÃ©
PensÃ©e : Je vais transmettre cette info.
RÃ©ponse : Il fait 21Â°C et ensoleillÃ© Ã  Toulouse.

==================== SLIDE ====================
ğŸ›°ï¸ Model Context Protocol (MCP)

Un nouveau standard pour connecter les modÃ¨les aux outils.

Objectif : permettre aux modÃ¨les dâ€™interagir avec des systÃ¨mes externes via une interface standardisÃ©e.

AdoptÃ© par Anthropic, OpenAI et la communautÃ© open-source.

DÃ©finit :
- Serveurs = outils, ressources, schÃ©mas
- Clients = environnements dâ€™exÃ©cution des LLMs
- ModÃ¨les = consomment des rÃ©ponses structurÃ©es

==================== SLIDE ====================
ğŸ§± Architecture MCP

Ã‰tapes :

1. Le modÃ¨le envoie une requÃªte (list_resources, invoke_toolâ€¦)
2. Le serveur MCP exÃ©cute et renvoie du JSON structurÃ©
3. Le modÃ¨le intÃ¨gre la rÃ©ponse dans son raisonnement

Exemple :
{
  "name": "get_weather",
  "parameters": { "city": "Toulouse" },
  "returns": { "temp": "float", "condition": "string" }
}

==================== SLIDE ====================
âš–ï¸ MCP vs autres architectures

FonctionnalitÃ© | Function Calling | LangChain | MCP
NeutralitÃ© fournisseur | non | non | oui
Registre de schÃ©mas | partiel | oui | oui
ContrÃ´le par le modÃ¨le | oui | oui | oui
Outils plug-and-play | non | partiel | oui

==================== SLIDE ====================
ğŸ“¡ MCP : le â€œHTTP de lâ€™usage dâ€™outils par les agentsâ€.

Exemples propriÃ©taires :
- Claude 3 + MCP : systÃ¨mes de fichiers, API
- Gemini 1.5 : raisonnement multimodal + mÃ©moire
- GPT-4o : voix en temps rÃ©el + outils visuels

==================== SLIDE ====================
ğŸ§ª DÃ©mo open-source : â€œAssistant de recherche autonomeâ€

Stack :
- Llama-3 8B (Ollama / LM Studio)
- LangGraph ou CrewAI
- Arxiv API via MCP + mÃ©moire RAG locale

Objectif : rÃ©sumer des articles sur le Topic Modeling

==================== SLIDE ====================
DÃ©roulement de la dÃ©mo

1. Lâ€™utilisateur demande : â€œTrouve 3 articles rÃ©cents sur les diffusion transformers.â€
2. Lâ€™agent :
   - Interroge Arxiv
   - RÃ©sume les abstracts
   - Classe les rÃ©sultats
   - Produit un rapport
3. RÃ©sultat affichÃ© en terminal ou web

==================== SLIDE ====================
Autre dÃ©mo : Agent vocal (100% open source)

Stack :
- Whisper (STT)
- Llama-3 (raisonnement)
- Piper / Coqui (TTS)
- MCP pour les tÃ¢ches

Exemple :
â€œAssistant, rÃ©sume les actualitÃ©s IA du jour.â€
â†’ RÃ©ponse parlÃ©e gÃ©nÃ©rÃ©e localement.

==================== SLIDE ====================
ğŸ§­ DÃ©fis

- FiabilitÃ© & rÃ©duction des hallucinations
- CohÃ©rence de la mÃ©moire & objectifs long terme
- SÃ©curitÃ© & sandboxing
- MÃ©triques dâ€™Ã©valuation de lâ€™autonomie

==================== SLIDE ====================
ğŸ”® Futur

- Collaboration multi-agents
- Agents incarnÃ©s (robotique)
- Utilisation dâ€™outils fine-tuned (Toolformer)
- OS dâ€™Agents (infrastructure MCP)

Les agents deviennent une nouvelle couche dâ€™abstraction â€” un â€œcontainerâ€ pour la cognition.

==================== SLIDE ====================
ğŸ§© Ã€ retenir

- Les LLMs sont des moteurs de raisonnement
- Les agents leur donnent des outils, de la mÃ©moire et des objectifs
- MCP standardise une interopÃ©rabilitÃ© sÃ»re
- Lâ€™open-source permet des agents locaux et autonomes

==================== SLIDE ====================
ğŸ“š Ã€ lire

- ReAct (Yao et al., 2022)
- Toolformer (Schick et al., 2023)
- Model Context Protocol Spec (2024)
- LangChain / LangGraph
- CrewAI / AutoGen

==================== SLIDE ====================
ğŸ™ Merci !

â€œLes LLMs nous ont donnÃ© le raisonnement. MCP leur donne lâ€™agence.â€
Questions ?
